{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500 Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project overview\n",
    "The following project aims to get data on all stocks in the S&P500 index by using the Alpha Vantage API. Following this, we choose some big-tech company stocks and present their prices in an interactive figure. Lastly, we identify stocks exhibiting short-term momentum.\n",
    "\n",
    "**Note :** \n",
    "Please don't run the cell that calls the API, since it will run for about 2 hours. We have completed that step locally and saved the resulting dataset locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and set magics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from alpha_vantage.timeseries import TimeSeries # Enables the use of Alpha Vantage stock API\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "\n",
    "# b. Autoreload\n",
    "\n",
    "# autoreload modules when code is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# local modules\n",
    "# import dataproject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Call, read, clean and present data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all S&P500 tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read all S&P500 tickers** from ``http://en.wikipedia.org/wiki/List_of_S%26P_500_companies`` and **save it** as variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Read\n",
    "\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker)\n",
    "        \n",
    "    with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tickers,f)\n",
    "        \n",
    "    return tickers\n",
    "\n",
    "# b. Save\n",
    "\n",
    "tickers = save_sp500_tickers()\n",
    "tickers = [x[:-1] for x in tickers]\n",
    "\n",
    "# c. Replacing ticker names that later produces errors:\n",
    "\n",
    "tickers = [w.replace('BF.B', 'BF-B') for w in tickers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 5 ticker namesnow looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tickers[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call API to get all S&P500 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Call Alpha Vantage API to get all S&P500 monthly stock prices** and **save it** as dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'IHXRIDZAXOXUHF8T' # PERSONAL AlphaVantage API key. Please, don't abuse/redistribute.\n",
    "\n",
    "ETFs = np.array(tickers) # All S&P 500 tickers used.\n",
    "\n",
    "ts = TimeSeries(key = api_key, output_format = 'pandas', indexing_type='date') # From alpha_vantage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DON'T RUN THE FOLLOWING CELL**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data = pd.DataFrame()\n",
    "\n",
    "# Loop through requested stocks.\n",
    "\n",
    "print('Querying Securities, Estimated time: ' + str(round(len(ETFs)/5)) + ' minutes') # Message for estimated time left.\n",
    "for x in range(len(ETFs)):\n",
    "    print(str(ETFs[x]))\n",
    "\n",
    "    if (x + 1) % 5 == 0:\n",
    "        time.sleep(60) # The free version of the API is limited to 5 calls per minute.\n",
    "\n",
    "    data, meta_data = ts.get_monthly_adjusted(symbol=str(ETFs[x])) \n",
    "    data = data['5. adjusted close'].iloc[::-1]             \n",
    "    data = pd.DataFrame(data).rename(index=str, columns={'5. adjusted close' : str(ETFs[x])})\n",
    "    price_data = pd.concat([price_data,data], axis=1, sort=False)\n",
    "    \n",
    "price_data = price_data.iloc[:300].iloc[::-1]\n",
    "\n",
    "plt.plot(price_data)\n",
    "plt.xticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create **local copy** for future references so the API that takes hours to run won't have to be called more than once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localdata = price_data.copy()\n",
    "\n",
    "localdata.to_csv(r'C:\\Users\\07anl_000\\Desktop\\Polit - KU\\Kandidat\\3. semester\\Seminar Anv. Corp Fin\\localdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading dataset from local path**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\07anl_000\\Desktop\\Polit - KU\\Kandidat\\3. semester\\Seminar Anv. Corp Fin\\localdata.csv', delimiter = \",\", index_col = 'Unnamed: 0')\n",
    "df = df.reindex(index = df.index[::-1]) # Changing the order of rows.\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subsetting** a couple of big tech company stocks to focus on in the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big = df[['MSFT', 'AMZN', 'AAPL', 'GOOG', 'FB']] # Choosing certain big tech stocks for the interactive figures.\n",
    "\n",
    "df_big['Date'] = df.index\n",
    "\n",
    "df_big['Date'] = pd.to_datetime(df_big.Date)\n",
    "\n",
    "df_big['Date'] = df_big['Date'].dt.strftime('%m/%Y')\n",
    "\n",
    "df_big = df_big.drop(df.index[0 : 169]) # Deleting rows to enhance the graph and only show returns from past couple of years.\n",
    "\n",
    "print(df_big.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating** an **interactive figure** to show the development of stock prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Initialize figure\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# b. Add scatters for each big tech ticker\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x = list(df_big.Date), y = list(df_big.MSFT) , name = 'Microsoft'))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x = list(df_big.Date), y = list(df_big.AMZN) , name = 'Amazon'))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x = list(df_big.Date), y = list(df_big.AAPL) , name = 'Apple'))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x = list(df_big.Date), y = list(df_big.FB) , name ='Facebook'))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x = list(df_big.Date), y = list(df_big.GOOG) , name = 'Google'))\n",
    "\n",
    "# c. Add slicer\n",
    "\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            active=0,\n",
    "            buttons=list([\n",
    "                dict(label=\"None\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, True, True, True, True]}]),\n",
    "                dict(label=\"Microsoft\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False, False]}]),\n",
    "                dict(label=\"Amazon\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [False, True, False, False, False]}]),\n",
    "                dict(label=\"Apple\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [False, False, True, False, False]}]),\n",
    "                dict(label=\"Facebook\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [False, False, False, True, False]}]),\n",
    "                dict(label=\"Google\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [False, False, False, False, True]}])\n",
    "            ]),\n",
    "        )\n",
    "    ])\n",
    "\n",
    "# d. Add creative title and display\n",
    "\n",
    "fig.update_layout(title_text=\"STONKS\" , yaxis_title = 'Adj. Close')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the data for momentum signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating returns and identifying momentum stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df = df.copy() # Copy of dataset, to make return calculations\n",
    "\n",
    "returns_df = returns_df.apply(lambda x: x.shift(-1)/x - 1, axis = 0) # Monthly returns \n",
    "\n",
    "nreturns_df = returns_df.shift(1, axis = 0) # Offsets the rows by 1, to make the results more intuitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accumulating returns to define winners and losers**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creturns_df = nreturns_df.copy()\n",
    "\n",
    "creturns_df = creturns_df.apply(lambda x : x + x.shift(1) + x.shift(2) + x.shift(3) + x.shift(4) + x.shift(5), axis = 0) \n",
    "# Accumulating returns for the previous 6 months\n",
    "\n",
    "creturns_df = creturns_df.shift(1, axis = 0) #Offsets values\n",
    "\n",
    "print(creturns_df.iloc[0:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining winners and losers based on distribution**\n",
    "\n",
    "Stocks in the top 30 percentiles, have strong positive momentum signals, and should therefore be bought.\n",
    "\n",
    "Likewise stocks in the bottom 30 percentiles have strong negative momentum signals and should therefore be shorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreturns_df = creturns_df.copy()\n",
    "\n",
    "dreturns_df = dreturns_df.transpose() # Transposes the dataset, so it's applicable for .describe()\n",
    "\n",
    "perc = [0.3, 0.7] # Defining lower and upper bounds\n",
    "\n",
    "dreturns_df.describe(percentiles = perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of percentiles on different dates\n",
    "\n",
    "percentiles = pd.DataFrame()\n",
    "\n",
    "percentiles['lower bound'] = dreturns_df.quantile(0.3)\n",
    "percentiles['upper bound'] = dreturns_df.quantile(0.7)\n",
    "\n",
    "print(percentiles.iloc[[-4], [0,1]]) #\n",
    "\n",
    "# Adding bounds to dataframe , to quickly compare whether stocks are winners or losers\n",
    "\n",
    "creturns_df['lower bound'] = percentiles['lower bound']\n",
    "creturns_df['upper bound'] = percentiles['upper bound']\n",
    "\n",
    "print(creturns_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing stock performance and bounds to see if they exhibit momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compares if the Big-Tech stocks are \"Winners\" or \"Losers\"\n",
    "\n",
    "print(creturns_df.loc['29-11-2019 00:00' , ['MSFT', 'AMZN', 'AAPL', 'GOOG', 'FB' , 'lower bound' , 'upper bound']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is **evident** that neither **Microsoft**, **Google** nor **Facebook** exhibit momentum, granted they fall *within* the bounds.\n",
    "\n",
    "**However**, the **Apple** stock exhibits **positive short-term momentum** (*long signal*), whilst the **Amazon** stock exhibits **negative short-term momentum** (*short signal*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have shown how easily stock price data may be called from an API and how it is easily vizualised. Furthermore, we have analyzed the data and offered a trading recommendation based on a simple version of a momentum strategy (Evaluate 6 months and hold stocks for 6 months)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
